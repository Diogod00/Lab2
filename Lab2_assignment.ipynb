{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Diogod00/Lab2/blob/DiogoDantas/Lab2_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratory Session 2 -- Assignment\n",
        "\n",
        "To be delivered until 2021-12-20 23:59:59."
      ],
      "metadata": {
        "id": "JV5YbbVNlCLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1 -- Linear Regression\n",
        "\n",
        "**1.** Consider a dataset with 100 observations, containing a single predictor and a quantitative response. Two different models are fitted to the data, a linear regression ($m_1: Y = \\beta_0 + \\beta_1 X + \\epsilon$) and a cubic regression ($m_2: Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon$)."
      ],
      "metadata": {
        "id": "A746fsNRldR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.a)** Suppose that the actual relation between X and Y is linear. Can the **training** residual sum of squares (RSS) of the linear model be expected to be smaller, larger or equal to the one from the cubic model? Or is there no information to tell? Justify your answer."
      ],
      "metadata": {
        "id": "gOuCfx3sm8hZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.b)** Answer question 1.a) considering the test RSS rather than the training RSS."
      ],
      "metadata": {
        "id": "f-Z6e3nem88s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.c)** Suppose that the actual relationship between X and Y is not linear, but it is not known how far it is from being linear. What is it expected of the the **training** RSS for the linear compared with the cubic models? Or is there not enough information? Justify your answer."
      ],
      "metadata": {
        "id": "gmhX35ckm9St"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.d)** Answer question 1.c) considering the test RSS rather than the training RSS."
      ],
      "metadata": {
        "id": "68b9Gt-Sm9lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.a)** Load the dataset \"auto.csv\" "
      ],
      "metadata": {
        "id": "JlY6gihzHUm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.b)** Perform a simple linear regression considering *mpg* as the response and *horsepower* as the predictor. Given the results, comment on the following statements:"
      ],
      "metadata": {
        "id": "BM90R_i8OCik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    i) Are the predictor and response statistically related?"
      ],
      "metadata": {
        "id": "2BlMbcTJOsDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    ii) How strong is the relationship between predictor and response? (*Hint: comment on the R^2 score of the model*)"
      ],
      "metadata": {
        "id": "ir5VRfrmO8o6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    iii) Is the relationship between the predictor and response positive or negative?"
      ],
      "metadata": {
        "id": "D9JSjxC3O8x3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    iv) What is the predicted value of mpg when the horsepower is 98?"
      ],
      "metadata": {
        "id": "mIzssLawO84u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.c)** Plot a scatter plot of the response and predictor, along with the regression line."
      ],
      "metadata": {
        "id": "yRYL0_TeQQfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2 -- Classification"
      ],
      "metadata": {
        "id": "1xBHkVadQ5Ot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3)** Suppose that a dataset is divided into two equally-sized training and test sets, and then try out two different classification procedures:\n",
        "\n",
        "* The first is the logistic regression, obtaining an error rate of 20% on the training data and 30% on the test data.\n",
        "* The second is a 1-nearest neighbors, with an average error rate (averaged over test and training datasets) of 18%.\n",
        "\n",
        "Based on these results, which method is preferred for classifying new observations? Why?"
      ],
      "metadata": {
        "id": "SIpGTVYkRD9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quando se menciona 1-nearest neighbors, assumimos que **K=1** (o dataset irá dividir-se em 1 parte). Isto significa que este método irá escolher a amostra de treino mais próxima da nossa amostra de teste para validação. Visto que a nossa amostra de teste se encontra no dataset de treino, tendo em conta que apenas temos uma parte, o vizinho mais próximo será o prórprio dado. Podemos então assumir que o **erro de treino** quando K=1 é de **0%**.\n",
        "\n",
        "Para a classificação de novas observações, interessa-nos o error test, visto que é este que está associado ao erro médio proveniente da predição da resposta a estes novos dados. \n",
        "\n",
        "Do enunciado tiramos que para o método de 1-nearest neighbors temos uma média entre teste e treino de 18%, e sendo o erro de treino 0%, conclui-se que o **erro de teste** é então **36%**. \n",
        "\n",
        "Sendo este superior a 30%, que é a taxa de erro de teste usando logistic regression, pode-se dizer que o método preferencial para classificar novas observações neste caso é o **logistic regression**."
      ],
      "metadata": {
        "id": "QGg1FvtWgfsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.a)** Load the dataset \"auto.csv\""
      ],
      "metadata": {
        "id": "z0Ws08q_SVLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.b)** Create a new column, \"mpg01\", that contains a 1 if mpg contains a value above its median, and a 0 if mpg contains a value below its median."
      ],
      "metadata": {
        "id": "rpJxxZkFSjg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.c)** Do a scatterplot matrix between the columns to evaluate which other features seem most likely to be useful in predicting mpg01. Consider dropping the columns origin and name as they are categorical. Describe your findings."
      ],
      "metadata": {
        "id": "xHvwjfYscqAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.d)** Drop the \"name\" and the \"mpg\" columns (the original mpg, not the mpg01). Create two new columns named \"origin1\" and \"origin2\". The first takes the value 1 when column origin is 1, and 0 otherwise; the second takes the value 1 when the column origin is 2 and 0 otherwise. Then, drop column origin."
      ],
      "metadata": {
        "id": "kLf3_ufHhDbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.e)** Split the data into test and training datasets. Consider a test dataset comprised of 30% of the whole dataset."
      ],
      "metadata": {
        "id": "8168IcmcSjd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.f)** Perform LDA on the training data in order to predict mpg01 using the remaining variables. What is the test error of the model obtained?"
      ],
      "metadata": {
        "id": "IWepa-QISjbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.g)** Perform QDA on the training data in order to predict mpg01 using the remaining variables. What is the test error of the model obtained?"
      ],
      "metadata": {
        "id": "YWiMguFvSjWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.h)** Perform logistic regression on the training data in order to predict mpg01 using the remaining variables. What is the test error of the model obtained?"
      ],
      "metadata": {
        "id": "DFAhEuhSSjOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.i)** Perform naive Bayes on the training data in order to predict mpg01 using the remaining variables. What is the test error of the model obtained?"
      ],
      "metadata": {
        "id": "dJUvW41ViqMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.j)** Perform KNN on the training data, with several values of K, in order to predict mpg01. Use only the variables \"displacement\", \"horsepower\", and \"weight\". What test errors are obtained? Which value of K seems to perform the best on this data set?"
      ],
      "metadata": {
        "id": "tPRBsCLviqKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.k)** Calculate the area under curve (AUC) for the LDA, QDA, logistic regression, naive Bayes and for the best value of K for the KNN method. Compare the results."
      ],
      "metadata": {
        "id": "nvhamoK0i2WZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3 -- Bootstrap and k-Fold"
      ],
      "metadata": {
        "id": "jEtBKnHni2GT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.a)** Explain how k-fold cross-validation is implemented"
      ],
      "metadata": {
        "id": "AyCSRMx2pDsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtendo os dados, dividimos os mesmos aleatoriamente em K partes aproximadamente do mesmo tamanho. De seguida admitimos que a primeira parte como validation data e introduzimos o modelo nas restantes k-1 partes. Calcula-se o mean square error (MSE) nas observações das k-1 partes. Depois repetimos o processo k vezes de forma a que todas as partes sejam vistas como validation data, calculando para cada o MSE. No final calcula-se o k-fold cross validation através da equação apresentada nas teóricas."
      ],
      "metadata": {
        "id": "Q_s0VTqqKTKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.b)** What are the advantages and disadvantages of k-Fold cross-validation relative to:\n",
        "\n",
        "1. Validation set approach.\n",
        "2. Leave One Out Cross-Validation (LOOCV)"
      ],
      "metadata": {
        "id": "MbIethdmpcwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation set approach**: \n",
        "\n",
        "*   Vantagens: Validation Set Approach é altamente variável porque depende do tipo de observações que serão incluidas nos dados de treino e nos dados de validação. Neste método apenas uma parte das observações (dados de treino) é usada. Visto que os métodos estatísticos têm melhores respostas quando maior for o número de dados observados (o que não acontece neste caso) o erro de validação terá a tendência de estimar em excesso o erro de teste em todo o dataset.\n",
        "*   Desvantagens: Validation Set Approach é mais simples e fácil de modelar.\n",
        "\n",
        "**LOOCV**: \n",
        "\n",
        "*   Vantagens: \n",
        "*   Desvantagens:"
      ],
      "metadata": {
        "id": "qmhCld_Bj6W1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4 -- Other Questions"
      ],
      "metadata": {
        "id": "jOcCUxFMpAGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6)** In your group's option, what are the advantages and disadvantages of using a virtual environment when programming in Python?"
      ],
      "metadata": {
        "id": "jUkJU0D7pFWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7)** In your group's opinion, in what circumstances is it better to use Jupyter Notebooks and when is it better to use Google Colab notebooks? Give some specific examples."
      ],
      "metadata": {
        "id": "W8dWu7BXpFTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8)** Enter your GitHub repository webpage."
      ],
      "metadata": {
        "id": "Sl0krfG6pFH6"
      }
    }
  ]
}